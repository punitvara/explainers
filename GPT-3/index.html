<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>GPT-3: Language Models are Few-Shot Learners ‚Äî An Interactive Explainer</title>
<style>
:root {
  --bg: #fafaf8;
  --text: #1a1a1a;
  --accent: #2563eb;
  --accent-light: #dbeafe;
  --muted: #6b7280;
  --callout-bg: #f8f5f0;
  --callout-border: #d4a574;
  --demo-bg: #ffffff;
  --demo-border: #e5e5e5;
  --green: #16a34a;
  --red: #dc2626;
  --orange: #ea580c;
  --purple: #7c3aed;
}

* { margin: 0; padding: 0; box-sizing: border-box; }

body {
  background: var(--bg);
  color: var(--text);
  font-family: Georgia, 'Times New Roman', serif;
  font-size: 19px;
  line-height: 1.75;
  -webkit-font-smoothing: antialiased;
}

.content {
  max-width: 680px;
  margin: 0 auto;
  padding: 0 24px;
}

/* Hero */
.hero {
  text-align: center;
  padding: 100px 24px 60px;
  max-width: 780px;
  margin: 0 auto;
}
.hero h1 {
  font-family: Georgia, serif;
  font-size: 46px;
  line-height: 1.15;
  font-weight: 700;
  margin-bottom: 16px;
  color: var(--text);
}
.hero .subtitle {
  font-family: system-ui, -apple-system, sans-serif;
  font-size: 18px;
  color: var(--muted);
  margin-bottom: 12px;
}
.hero .paper-ref {
  font-family: system-ui, -apple-system, sans-serif;
  font-size: 14px;
  color: var(--accent);
  font-style: italic;
}
.hero .meta {
  font-family: system-ui, -apple-system, sans-serif;
  font-size: 14px;
  color: var(--muted);
  margin-top: 24px;
}
.hero .meta span { margin: 0 8px; }

/* Table of Contents */
.toc {
  background: var(--callout-bg);
  border: 1px solid var(--callout-border);
  border-radius: 12px;
  padding: 32px 36px;
  margin: 40px auto;
  max-width: 680px;
}
.toc h2 {
  font-family: system-ui, sans-serif;
  font-size: 14px;
  text-transform: uppercase;
  letter-spacing: 2px;
  color: var(--muted);
  margin-bottom: 16px;
}
.toc ol {
  list-style: none;
  counter-reset: toc-counter;
}
.toc ol li {
  counter-increment: toc-counter;
  margin-bottom: 8px;
}
.toc ol li::before {
  content: counter(toc-counter, upper-roman) ". ";
  font-family: system-ui, sans-serif;
  font-weight: 600;
  color: var(--accent);
  margin-right: 4px;
}
.toc a {
  color: var(--text);
  text-decoration: none;
  font-size: 17px;
  transition: color 0.2s;
}
.toc a:hover { color: var(--accent); }

/* Section Headings */
h2.section-title {
  font-size: 32px;
  font-weight: 700;
  margin: 80px 0 24px;
  line-height: 1.25;
  color: var(--text);
}
h2.section-title .section-num {
  color: var(--accent);
  font-family: system-ui, sans-serif;
  font-size: 15px;
  display: block;
  text-transform: uppercase;
  letter-spacing: 2px;
  margin-bottom: 6px;
}
h3 {
  font-size: 24px;
  margin: 40px 0 16px;
  font-weight: 600;
}
h4 {
  font-size: 20px;
  margin: 24px 0 12px;
  font-weight: 600;
}

/* Paragraphs */
p {
  margin-bottom: 18px;
}
strong { font-weight: 700; }

/* Callout */
.callout {
  background: var(--callout-bg);
  border-left: 4px solid var(--callout-border);
  padding: 20px 24px;
  margin: 28px 0;
  border-radius: 0 8px 8px 0;
  font-size: 17px;
}
.callout.blue {
  background: var(--accent-light);
  border-left-color: var(--accent);
}
.callout p:last-child { margin-bottom: 0; }

/* Demo Containers */
.demo-container {
  background: var(--demo-bg);
  border: 1px solid var(--demo-border);
  border-radius: 14px;
  padding: 28px;
  margin: 32px -50px;
  max-width: 780px;
  box-shadow: 0 2px 12px rgba(0,0,0,0.04);
}
@media (max-width: 820px) {
  .demo-container { margin-left: 0; margin-right: 0; max-width: 100%; }
}
.demo-container h4 {
  font-family: system-ui, sans-serif;
  font-size: 14px;
  text-transform: uppercase;
  letter-spacing: 1.5px;
  color: var(--accent);
  margin: 0 0 18px 0;
}
.demo-caption {
  font-family: system-ui, sans-serif;
  font-size: 13px;
  color: var(--muted);
  text-align: center;
  margin-top: 14px;
  font-style: italic;
}

/* Buttons */
.btn {
  font-family: system-ui, sans-serif;
  font-size: 14px;
  font-weight: 600;
  padding: 8px 20px;
  border-radius: 8px;
  border: none;
  cursor: pointer;
  transition: all 0.2s;
}
.btn-primary {
  background: var(--accent);
  color: white;
}
.btn-primary:hover { background: #1d4ed8; }
.btn-outline {
  background: transparent;
  border: 2px solid var(--accent);
  color: var(--accent);
}
.btn-outline:hover { background: var(--accent-light); }
.btn-sm { padding: 5px 14px; font-size: 13px; }

/* Sliders */
input[type="range"] {
  -webkit-appearance: none;
  width: 100%;
  height: 6px;
  border-radius: 3px;
  background: #e2e2e2;
  outline: none;
  margin: 12px 0;
}
input[type="range"]::-webkit-slider-thumb {
  -webkit-appearance: none;
  width: 22px;
  height: 22px;
  border-radius: 50%;
  background: var(--accent);
  cursor: pointer;
  box-shadow: 0 2px 6px rgba(37,99,235,0.3);
}

/* Tags */
.tag {
  display: inline-block;
  font-family: system-ui, sans-serif;
  font-size: 12px;
  font-weight: 600;
  padding: 3px 10px;
  border-radius: 20px;
  margin: 2px 4px;
}
.tag-blue { background: var(--accent-light); color: var(--accent); }
.tag-green { background: #dcfce7; color: var(--green); }
.tag-orange { background: #ffedd5; color: var(--orange); }
.tag-purple { background: #ede9fe; color: var(--purple); }
.tag-red { background: #fef2f2; color: var(--red); }

/* Code */
code {
  font-family: 'SF Mono', 'Fira Code', monospace;
  font-size: 15px;
  background: #f3f3f0;
  padding: 2px 7px;
  border-radius: 4px;
}
pre {
  background: #1e1e2e;
  color: #cdd6f4;
  padding: 20px 24px;
  border-radius: 10px;
  overflow-x: auto;
  margin: 20px 0;
  font-size: 14px;
  line-height: 1.6;
}
pre code {
  background: none;
  padding: 0;
  color: inherit;
  font-size: 14px;
}

/* Animated bars */
.bar-chart { display: flex; flex-direction: column; gap: 10px; }
.bar-row {
  display: flex;
  align-items: center;
  gap: 12px;
  font-family: system-ui, sans-serif;
  font-size: 14px;
}
.bar-label {
  min-width: 120px;
  text-align: right;
  font-weight: 600;
  font-size: 13px;
}
.bar-track {
  flex: 1;
  height: 28px;
  background: #f0f0f0;
  border-radius: 6px;
  overflow: hidden;
  position: relative;
}
.bar-fill {
  height: 100%;
  border-radius: 6px;
  transition: width 1.2s cubic-bezier(0.22, 1, 0.36, 1);
  display: flex;
  align-items: center;
  padding-left: 10px;
  font-family: system-ui, sans-serif;
  font-size: 12px;
  font-weight: 700;
  color: white;
  white-space: nowrap;
}
.bar-value {
  min-width: 60px;
  font-weight: 700;
  color: var(--text);
  font-size: 13px;
}

/* Comparison table */
.comp-table {
  width: 100%;
  border-collapse: collapse;
  font-family: system-ui, sans-serif;
  font-size: 14px;
  margin: 16px 0;
}
.comp-table th {
  text-align: left;
  padding: 10px 12px;
  font-size: 12px;
  text-transform: uppercase;
  letter-spacing: 1px;
  color: var(--muted);
  border-bottom: 2px solid #e5e5e5;
}
.comp-table td {
  padding: 10px 12px;
  border-bottom: 1px solid #f0f0f0;
}
.comp-table tr:hover { background: #fafaf8; }
.comp-table .highlight { background: var(--accent-light); font-weight: 700; }

/* Interactive prompt demo */
.prompt-box {
  background: #1e1e2e;
  border-radius: 10px;
  padding: 20px;
  font-family: 'SF Mono', 'Fira Code', monospace;
  font-size: 14px;
  color: #cdd6f4;
  min-height: 120px;
  margin: 12px 0;
}
.prompt-label {
  color: #89b4fa;
  font-weight: 700;
}
.prompt-text { color: #a6e3a1; }
.prompt-completion {
  color: #f9e2af;
  opacity: 0;
  transition: opacity 0.5s;
}
.prompt-completion.visible { opacity: 1; }
.typing-cursor {
  display: inline-block;
  width: 2px;
  height: 16px;
  background: #f9e2af;
  animation: blink 0.8s infinite;
  vertical-align: middle;
  margin-left: 2px;
}
@keyframes blink { 0%,50% { opacity: 1; } 51%,100% { opacity: 0; } }

/* Token animation */
.token-stream {
  display: flex;
  flex-wrap: wrap;
  gap: 6px;
  margin: 12px 0;
  min-height: 44px;
}
.token {
  display: inline-block;
  font-family: system-ui, sans-serif;
  font-size: 14px;
  font-weight: 600;
  padding: 6px 12px;
  border-radius: 8px;
  transition: all 0.3s;
  cursor: default;
}
.token.input-token { background: var(--accent-light); color: var(--accent); }
.token.output-token { background: #fef3c7; color: #92400e; }
.token.attn-token { background: #ede9fe; color: var(--purple); }
.token:hover { transform: translateY(-2px); box-shadow: 0 4px 8px rgba(0,0,0,0.1); }

/* Layer viz */
.layer-stack {
  display: flex;
  flex-direction: column;
  gap: 4px;
  margin: 16px 0;
}
.layer-block {
  height: 10px;
  border-radius: 3px;
  transition: all 0.4s;
  cursor: pointer;
  position: relative;
}
.layer-block:hover {
  transform: scaleY(2.5);
  box-shadow: 0 2px 8px rgba(0,0,0,0.15);
}
.layer-block .layer-tooltip {
  position: absolute;
  left: 50%;
  top: -32px;
  transform: translateX(-50%);
  background: var(--text);
  color: white;
  font-family: system-ui, sans-serif;
  font-size: 12px;
  padding: 4px 10px;
  border-radius: 6px;
  white-space: nowrap;
  opacity: 0;
  pointer-events: none;
  transition: opacity 0.2s;
}
.layer-block:hover .layer-tooltip { opacity: 1; }

/* Quiz */
.quiz-option {
  display: block;
  width: 100%;
  text-align: left;
  font-family: system-ui, sans-serif;
  font-size: 15px;
  padding: 12px 18px;
  margin: 6px 0;
  border: 2px solid var(--demo-border);
  border-radius: 10px;
  background: white;
  cursor: pointer;
  transition: all 0.2s;
}
.quiz-option:hover { border-color: var(--accent); background: var(--accent-light); }
.quiz-option.correct { border-color: var(--green); background: #dcfce7; }
.quiz-option.wrong { border-color: var(--red); background: #fef2f2; }
.quiz-feedback {
  font-family: system-ui, sans-serif;
  font-size: 14px;
  padding: 10px 16px;
  border-radius: 8px;
  margin-top: 10px;
  display: none;
}

/* Meter / gauge */
.gauge-row {
  display: flex;
  align-items: center;
  gap: 12px;
  margin: 8px 0;
  font-family: system-ui, sans-serif;
  font-size: 14px;
}
.gauge-label { min-width: 140px; font-weight: 600; }
.gauge-track {
  flex: 1;
  height: 12px;
  background: #f0f0f0;
  border-radius: 6px;
  overflow: hidden;
}
.gauge-fill {
  height: 100%;
  border-radius: 6px;
  transition: width 0.8s cubic-bezier(0.22,1,0.36,1);
}
.gauge-val { min-width: 50px; font-weight: 700; text-align: right; }

/* Step-through */
.step-nav {
  display: flex;
  justify-content: center;
  align-items: center;
  gap: 16px;
  margin: 16px 0;
  font-family: system-ui, sans-serif;
}
.step-counter {
  font-size: 14px;
  color: var(--muted);
  font-weight: 600;
}
.step-content {
  padding: 20px;
  background: #f9fafb;
  border-radius: 10px;
  min-height: 100px;
  transition: opacity 0.3s;
  font-size: 16px;
  line-height: 1.65;
}
.step-content strong { color: var(--accent); }

/* Interactive input demo */
.input-demo-area {
  margin: 12px 0;
}
.input-demo-area textarea {
  width: 100%;
  font-family: 'SF Mono', 'Fira Code', monospace;
  font-size: 14px;
  padding: 14px;
  border: 2px solid var(--demo-border);
  border-radius: 10px;
  resize: vertical;
  min-height: 60px;
  transition: border-color 0.2s;
}
.input-demo-area textarea:focus {
  outline: none;
  border-color: var(--accent);
}

/* Summary grid */
.summary-grid {
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 16px;
  margin: 20px 0;
}
@media (max-width: 600px) { .summary-grid { grid-template-columns: 1fr; } }
.summary-card {
  background: var(--callout-bg);
  border-radius: 12px;
  padding: 20px;
}
.summary-card h4 {
  font-family: system-ui, sans-serif;
  font-size: 13px;
  text-transform: uppercase;
  letter-spacing: 1px;
  color: var(--accent);
  margin: 0 0 8px 0;
}
.summary-card p {
  font-size: 15px;
  margin: 0;
}

/* Footer */
footer {
  text-align: center;
  padding: 60px 24px 40px;
  margin-top: 80px;
  border-top: 1px solid #e5e5e5;
  font-family: system-ui, sans-serif;
  font-size: 14px;
  color: var(--muted);
}
footer a { color: var(--accent); text-decoration: none; }
footer a:hover { text-decoration: underline; }

/* Links */
a { color: var(--accent); }
a:hover { text-decoration: underline; }

/* Scroll animations */
.fade-in {
  opacity: 0;
  transform: translateY(20px);
  transition: opacity 0.6s ease-out, transform 0.6s ease-out;
}
.fade-in.visible {
  opacity: 1;
  transform: translateY(0);
}

/* Dropdown / accordion */
.accordion-header {
  font-family: system-ui, sans-serif;
  font-size: 15px;
  font-weight: 600;
  padding: 12px 16px;
  background: #f9fafb;
  border: 1px solid var(--demo-border);
  border-radius: 8px;
  cursor: pointer;
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin: 6px 0;
  transition: background 0.2s;
}
.accordion-header:hover { background: var(--accent-light); }
.accordion-header .arrow { transition: transform 0.3s; }
.accordion-header.open .arrow { transform: rotate(180deg); }
.accordion-body {
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.4s ease;
  padding: 0 16px;
  font-size: 15px;
  line-height: 1.65;
}
.accordion-body.open {
  max-height: 600px;
  padding: 12px 16px;
}

/* Grid for icons */
.icon-grid {
  display: grid;
  grid-template-columns: repeat(3, 1fr);
  gap: 12px;
  margin: 16px 0;
}
@media (max-width: 600px) { .icon-grid { grid-template-columns: repeat(2, 1fr); } }
.icon-card {
  text-align: center;
  padding: 16px 10px;
  border-radius: 12px;
  border: 1px solid var(--demo-border);
  transition: all 0.25s;
  cursor: pointer;
  font-family: system-ui, sans-serif;
}
.icon-card:hover {
  border-color: var(--accent);
  background: var(--accent-light);
  transform: translateY(-3px);
  box-shadow: 0 4px 12px rgba(37,99,235,0.12);
}
.icon-card .icon-emoji { font-size: 28px; margin-bottom: 6px; }
.icon-card .icon-label { font-size: 12px; font-weight: 600; color: var(--muted); }
.icon-card .icon-value { font-size: 16px; font-weight: 700; margin-top: 2px; }

/* Horizontal scroll for cards */
.hscroll {
  display: flex;
  gap: 14px;
  overflow-x: auto;
  padding: 8px 0 16px;
  scroll-snap-type: x mandatory;
}
.hscroll::-webkit-scrollbar { height: 6px; }
.hscroll::-webkit-scrollbar-thumb { background: #d0d0d0; border-radius: 3px; }
.hscroll-card {
  min-width: 220px;
  scroll-snap-align: start;
  background: white;
  border: 1px solid var(--demo-border);
  border-radius: 12px;
  padding: 18px;
  font-family: system-ui, sans-serif;
  flex-shrink: 0;
}
.hscroll-card h5 {
  font-size: 14px;
  font-weight: 700;
  margin-bottom: 6px;
}
.hscroll-card p {
  font-size: 13px;
  color: var(--muted);
  margin: 0;
  line-height: 1.5;
}

/* Misc */
.highlight-number {
  font-family: system-ui, sans-serif;
  font-weight: 800;
  font-size: 48px;
  color: var(--accent);
  display: block;
  text-align: center;
  margin: 20px 0;
}
.flex-center { display: flex; justify-content: center; align-items: center; }
.mt-sm { margin-top: 10px; }
.mb-sm { margin-bottom: 10px; }
.text-center { text-align: center; }
.text-muted { color: var(--muted); }
.text-sm { font-size: 14px; font-family: system-ui, sans-serif; }
.fw-700 { font-weight: 700; }

.pill-row {
  display: flex;
  gap: 8px;
  flex-wrap: wrap;
  margin: 12px 0;
  justify-content: center;
}

/* SVG styles */
svg text {
  font-family: system-ui, sans-serif;
}
</style>
</head>
<body>

<!-- ========== HERO ========== -->
<header class="hero">
  <div class="subtitle">Interactive Explainer</div>
  <h1>GPT-3: Language Models<br>are Few-Shot Learners</h1>
  <p class="paper-ref">Brown et al., 2020 &middot; OpenAI</p>
  <div class="meta">
    <span>üìÑ ~6,500 words</span>
    <span>¬∑</span>
    <span>üß© 11 interactive demos</span>
    <span>¬∑</span>
    <span>‚è± 30 min read</span>
  </div>
</header>

<!-- ========== TABLE OF CONTENTS ========== -->
<nav class="toc content">
  <h2>Table of Contents</h2>
  <ol>
    <li><a href="#sec-opening">The Opening Salvo</a></li>
    <li><a href="#sec-scale">Scale Is All You Need (Almost)</a></li>
    <li><a href="#sec-architecture">The Decoder-Only Transformer</a></li>
    <li><a href="#sec-parameters">175 Billion Parameters</a></li>
    <li><a href="#sec-prompting">The Prompting Paradigm</a></li>
    <li><a href="#sec-icl">In-Context Learning</a></li>
    <li><a href="#sec-data">The Training Data</a></li>
    <li><a href="#sec-compute">Compute &amp; Training</a></li>
    <li><a href="#sec-benchmarks">Benchmark Results</a></li>
    <li><a href="#sec-limitations">Limitations &amp; Failure Modes</a></li>
    <li><a href="#sec-societal">Societal Implications</a></li>
    <li><a href="#sec-summary">Summary &amp; Legacy</a></li>
  </ol>
</nav>

<!-- ========== I. OPENING ========== -->
<article class="content">

<h2 class="section-title fade-in" id="sec-opening">
  <span class="section-num">I. The Opening Salvo</span>
  The Paper That Changed Everything
</h2>

<p class="fade-in">
  In May 2020, a team of researchers at OpenAI quietly uploaded a 75-page paper to arXiv. Its title was unassuming: <em>"Language Models are Few-Shot Learners."</em> Its contents were not. Inside those pages lay a demonstration so striking it would reshape the entire field of artificial intelligence ‚Äî and eventually, the world.
</p>

<p class="fade-in">
  The core claim was almost absurdly simple: <strong>make a language model big enough, and it can learn new tasks from just a handful of examples, without any fine-tuning</strong>. No gradient updates. No task-specific training data. Just show it what you want in the prompt, and it... figures it out.
</p>

<p class="fade-in">
  This was GPT-3: a <strong>175-billion-parameter</strong> autoregressive language model. To appreciate why that number mattered, consider that GPT-2, its predecessor from just a year earlier, had 1.5 billion parameters. GPT-3 was <em>over 100√ó larger</em>. And the jump in capability wasn't linear ‚Äî it was qualitatively different. New abilities seemed to <em>emerge</em> from the sheer scale.
</p>

<div class="callout fade-in">
  <p>üéØ <strong>The key insight:</strong> Scale doesn't just make models <em>better</em> ‚Äî it makes them <em>different</em>. GPT-3 could do things that smaller models simply could not, no matter how hard you tried.</p>
</div>

<p class="fade-in">
  Let's start with a taste. Below is a toy simulation of what blew people's minds. You give GPT-3 a couple of examples, and it generalizes the pattern.
</p>

<!-- DEMO 1: Few-shot pattern completion -->
<div class="demo-container fade-in" id="demo-opening">
  <h4>üß™ Demo: Few-Shot Pattern Completion</h4>
  <p class="text-sm text-muted mb-sm">Click "Generate" to see how the model completes the pattern from just a few examples.</p>
  
  <div class="prompt-box" id="opening-prompt">
    <div><span class="prompt-label">English: </span><span class="prompt-text">sea otter</span></div>
    <div><span class="prompt-label">French: </span><span class="prompt-text">loutre de mer</span></div>
    <div style="height:8px"></div>
    <div><span class="prompt-label">English: </span><span class="prompt-text">cheese</span></div>
    <div><span class="prompt-label">French: </span><span class="prompt-text">fromage</span></div>
    <div style="height:8px"></div>
    <div><span class="prompt-label">English: </span><span class="prompt-text" id="opening-input-word">plumber</span></div>
    <div><span class="prompt-label">French: </span><span class="prompt-completion" id="opening-completion">plombier</span><span class="typing-cursor" id="opening-cursor" style="display:none"></span></div>
  </div>

  <div style="display:flex; gap:10px; align-items:center; margin-top:12px; flex-wrap:wrap;">
    <button class="btn btn-primary" onclick="runOpeningDemo()">Generate ‚ñ∂</button>
    <select id="opening-select" style="font-family:system-ui,sans-serif;font-size:14px;padding:6px 12px;border-radius:8px;border:1px solid #ddd;">
      <option value="plumber|plombier">plumber</option>
      <option value="butterfly|papillon">butterfly</option>
      <option value="computer|ordinateur">computer</option>
      <option value="knowledge|connaissance">knowledge</option>
    </select>
  </div>
  <div class="demo-caption">GPT-3 infers the task (English‚ÜíFrench translation) from two examples ‚Äî no fine-tuning required.</div>
</div>


<!-- ========== II. SCALE ========== -->
<h2 class="section-title fade-in" id="sec-scale">
  <span class="section-num">II. Scale Is All You Need (Almost)</span>
  When Bigger Means Smarter
</h2>

<p class="fade-in">
  The story of deep learning from 2017 to 2020 is, in many ways, a story about <strong>scaling laws</strong>. Researchers had noticed something peculiar: when you plotted model performance against the number of parameters (on a log scale), the curve was remarkably smooth and predictable. Double the parameters, and you get a consistent chunk of improvement.
</p>

<p class="fade-in">
  But GPT-3 revealed something more dramatic. As models scaled from millions to billions to hundreds of billions of parameters, <strong>entirely new capabilities appeared</strong> ‚Äî abilities that were absent at smaller scales. This phenomenon, later dubbed <strong>"emergent abilities,"</strong> meant the model wasn't just doing the same things better; it was doing <em>new things</em>.
</p>

<p class="fade-in">
  At 350 million parameters? The model can autocomplete sentences. At 13 billion? It can answer trivia. At 175 billion? It can write code, compose poetry, do arithmetic, and reason about analogies ‚Äî often from a single example. The transitions are abrupt and surprising.
</p>

<!-- DEMO 2: Scaling slider -->
<div class="demo-container fade-in" id="demo-scale">
  <h4>üß™ Demo: Emergent Abilities at Scale</h4>
  <p class="text-sm text-muted mb-sm">Drag the slider to increase model size and watch new abilities unlock.</p>
  
  <div style="display:flex;align-items:center;gap:16px;margin:8px 0;">
    <span class="text-sm fw-700" style="min-width:80px;">Parameters:</span>
    <input type="range" id="scale-slider" min="0" max="5" step="1" value="0" style="flex:1" oninput="updateScaleDemo()">
  </div>
  <div class="highlight-number" id="scale-number">125M</div>
  
  <div id="scale-abilities" style="margin:16px 0;">
    <div class="pill-row" id="scale-pills"></div>
  </div>
  
  <div class="step-content" id="scale-desc" style="font-size:15px;">
    <strong>GPT-3 Small (125M):</strong> Basic grammar and sentence completion. Can finish a sentence that you start. Struggles with facts and logic. Think of it as a very fast autocomplete.
  </div>
  
  <div class="demo-caption">Slide from 125M to 175B parameters. Each jump reveals qualitatively new behaviors.</div>
</div>

<p class="fade-in">
  This wasn't just an academic curiosity. It suggested a radical strategy: instead of designing clever architectures or curating task-specific datasets, you could just <strong>scale up a simple model and let the magic happen</strong>. It was controversial. It was expensive. And it turned out to be spectacularly effective.
</p>

<div class="callout blue fade-in">
  <p>üí° <strong>Scaling hypothesis:</strong> "Most of the performance gains of large language models can be attributed to three factors: <em>more parameters, more data, and more compute.</em>" This idea, formalized in OpenAI's scaling laws paper (Kaplan et al., 2020), was GPT-3's philosophical foundation.</p>
</div>


<!-- ========== III. ARCHITECTURE ========== -->
<h2 class="section-title fade-in" id="sec-architecture">
  <span class="section-num">III. The Decoder-Only Transformer</span>
  The Engine Under the Hood
</h2>

<p class="fade-in">
  GPT-3's architecture is, at its heart, a <strong>decoder-only Transformer</strong> ‚Äî the same design lineage that started with GPT-1 in 2018. If you've read about BERT (encoder-only) or the original Transformer (encoder-decoder), GPT takes the other path: <em>just the decoder half</em>, trained left-to-right.
</p>

<p class="fade-in">
  The core idea is <strong>autoregressive generation</strong>: given a sequence of tokens, predict the next one. Then append that prediction, and predict the next, and the next. It's like a very sophisticated game of word-by-word autocomplete. Every token can only "see" the tokens that came before it ‚Äî this is enforced by the <strong>causal attention mask</strong>.
</p>

<p class="fade-in">
  GPT-3 specifically uses <strong>96 Transformer layers</strong>, each with 96 attention heads, and an embedding dimension of 12,288. The context window is 2,048 tokens. Tokens flow through layers of <strong>multi-head self-attention</strong> and <strong>feed-forward networks</strong>, accumulating meaning and context as they go.
</p>

<!-- DEMO 3: Architecture visualizer -->
<div class="demo-container fade-in" id="demo-arch">
  <h4>üß™ Demo: GPT-3 Architecture Explorer</h4>
  <p class="text-sm text-muted mb-sm">Hover over each layer block to explore GPT-3's 96-layer stack. Click a component to learn more.</p>
  
  <div style="text-align:center;margin-bottom:16px;">
    <svg width="600" height="200" viewBox="0 0 600 200" id="arch-svg">
      <!-- Token input -->
      <rect x="20" y="160" width="560" height="30" rx="6" fill="#dbeafe" stroke="#2563eb" stroke-width="1.5"/>
      <text x="300" y="180" text-anchor="middle" font-size="12" font-weight="700" fill="#2563eb">Token Embeddings + Positional Encoding (d=12,288)</text>
      
      <!-- Arrow up -->
      <line x1="300" y1="155" x2="300" y2="140" stroke="#999" stroke-width="1.5" marker-end="url(#arrowhead)"/>
      
      <!-- Layer stack -->
      <rect x="100" y="60" width="400" height="75" rx="10" fill="#f8f5f0" stroke="#d4a574" stroke-width="1.5"/>
      <text x="300" y="82" text-anchor="middle" font-size="11" font-weight="700" fill="#1a1a1a">√ó 96 Transformer Decoder Blocks</text>
      <rect x="120" y="90" width="160" height="32" rx="6" fill="#ede9fe" stroke="#7c3aed" stroke-width="1" class="arch-clickable" data-info="attn"/>
      <text x="200" y="111" text-anchor="middle" font-size="11" font-weight="600" fill="#7c3aed">Multi-Head Attention</text>
      <rect x="320" y="90" width="160" height="32" rx="6" fill="#dcfce7" stroke="#16a34a" stroke-width="1" class="arch-clickable" data-info="ffn"/>
      <text x="400" y="111" text-anchor="middle" font-size="11" font-weight="600" fill="#16a34a">Feed-Forward Network</text>
      
      <!-- Arrow up -->
      <line x1="300" y1="55" x2="300" y2="40" stroke="#999" stroke-width="1.5" marker-end="url(#arrowhead)"/>
      
      <!-- Output -->
      <rect x="120" y="8" width="360" height="28" rx="6" fill="#fef3c7" stroke="#d97706" stroke-width="1.5"/>
      <text x="300" y="27" text-anchor="middle" font-size="12" font-weight="700" fill="#92400e">Output Logits ‚Üí Softmax ‚Üí Next Token</text>
      
      <defs>
        <marker id="arrowhead" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto">
          <polygon points="0 0, 8 3, 0 6" fill="#999"/>
        </marker>
      </defs>
    </svg>
  </div>

  <div id="arch-info" class="step-content" style="font-size:14px;">
    <strong>Click a component</strong> to learn more. GPT-3 repeats the decoder block 96 times ‚Äî the deepest Transformer at the time of publication.
  </div>

  <div style="margin-top:16px;">
    <p class="text-sm fw-700" style="margin-bottom:8px;">96 Layers Visualized (hover any block):</p>
    <div class="layer-stack" id="layer-stack-viz"></div>
  </div>
  
  <div class="demo-caption">Each of 96 layers refines the representation. Earlier layers handle syntax; later layers handle semantics and reasoning.</div>
</div>

<p class="fade-in">
  One subtle but important detail: GPT-3 uses <strong>alternating dense and locally-banded sparse attention patterns</strong> in some layers, inspired by the Sparse Transformer. This helps manage the quadratic cost of self-attention over 2,048 tokens.
</p>

<p class="fade-in">
  The beauty of this architecture is its <strong>simplicity</strong>. There's no task-specific head, no classification layer, no special tokens for different tasks. It's just next-token prediction, all the way down. Every downstream task ‚Äî translation, Q&A, summarization ‚Äî is reformulated as "given this text, what comes next?"
</p>


<!-- ========== IV. 175 BILLION ========== -->
<h2 class="section-title fade-in" id="sec-parameters">
  <span class="section-num">IV. 175 Billion Parameters</span>
  A New Order of Magnitude
</h2>

<p class="fade-in">
  Let's put 175 billion in perspective. If you printed each parameter as a single digit on a standard piece of paper (about 3,000 characters per page), you'd need roughly <strong>58 million pages</strong>. Stacked, that's a tower over 5 kilometers tall ‚Äî higher than any mountain base camp.
</p>

<p class="fade-in">
  But the real story isn't just GPT-3's size in isolation. It's the <strong>progression</strong>. The GPT lineage shows exponential growth: GPT-1 had 117M parameters, GPT-2 had 1.5B, and GPT-3 leapt to 175B. Each jump was roughly 10‚Äì100√ó larger. And at each jump, new capabilities appeared.
</p>

<!-- DEMO 4: Parameter comparison -->
<div class="demo-container fade-in" id="demo-params">
  <h4>üß™ Demo: Parameter Comparison</h4>
  <p class="text-sm text-muted mb-sm">Click "Animate" to see how GPT-3 dwarfs its predecessors. Toggle log scale for perspective.</p>
  
  <div style="display:flex;gap:10px;margin-bottom:16px;">
    <button class="btn btn-primary btn-sm" onclick="animateParamBars()">Animate ‚ñ∂</button>
    <button class="btn btn-outline btn-sm" id="log-toggle" onclick="toggleLogScale()">Switch to Log Scale</button>
  </div>
  
  <div class="bar-chart" id="param-bars">
    <div class="bar-row">
      <div class="bar-label">ELMo (2018)</div>
      <div class="bar-track"><div class="bar-fill" id="bar-elmo" style="width:0;background:#94a3b8;"></div></div>
      <div class="bar-value">94M</div>
    </div>
    <div class="bar-row">
      <div class="bar-label">GPT-1 (2018)</div>
      <div class="bar-track"><div class="bar-fill" id="bar-gpt1" style="width:0;background:#64748b;"></div></div>
      <div class="bar-value">117M</div>
    </div>
    <div class="bar-row">
      <div class="bar-label">BERT-L (2018)</div>
      <div class="bar-track"><div class="bar-fill" id="bar-bert" style="width:0;background:#7c3aed;"></div></div>
      <div class="bar-value">340M</div>
    </div>
    <div class="bar-row">
      <div class="bar-label">GPT-2 (2019)</div>
      <div class="bar-track"><div class="bar-fill" id="bar-gpt2" style="width:0;background:#ea580c;"></div></div>
      <div class="bar-value">1.5B</div>
    </div>
    <div class="bar-row">
      <div class="bar-label">T5-11B (2019)</div>
      <div class="bar-track"><div class="bar-fill" id="bar-t5" style="width:0;background:#16a34a;"></div></div>
      <div class="bar-value">11B</div>
    </div>
    <div class="bar-row">
      <div class="bar-label" style="color:var(--accent);font-size:14px;">GPT-3 (2020)</div>
      <div class="bar-track"><div class="bar-fill" id="bar-gpt3" style="width:0;background:var(--accent);"></div></div>
      <div class="bar-value" style="color:var(--accent);font-size:15px;">175B</div>
    </div>
  </div>
  
  <div class="demo-caption">On a linear scale, everything before GPT-3 is essentially invisible. Log scale reveals the exponential progression.</div>
</div>

<p class="fade-in">
  The paper actually tested <strong>eight different model sizes</strong>, from 125M to 175B. This wasn't just showing off ‚Äî it was a systematic study of how performance scales. They found that larger models were more <strong>sample-efficient</strong> at in-context learning: the 175B model could learn from 1 example what the 1.3B model needed 50 examples to figure out.
</p>

<div class="callout fade-in">
  <p>üìä <strong>GPT-3's vital stats:</strong> 96 layers, 96 attention heads per layer, embedding dimension of 12,288, context window of 2,048 tokens, batch size of 3.2 million tokens, trained on ~300 billion tokens. The weights alone require ~700 GB in float32.</p>
</div>


<!-- ========== V. PROMPTING PARADIGM ========== -->
<h2 class="section-title fade-in" id="sec-prompting">
  <span class="section-num">V. The Prompting Paradigm</span>
  Zero-Shot, One-Shot, Few-Shot
</h2>

<p class="fade-in">
  Before GPT-3, the standard recipe for NLP was: (1) pre-train a big model on lots of text, then (2) <strong>fine-tune</strong> it on labeled data for your specific task. This required collecting task-specific datasets, running gradient updates, and maintaining separate model copies for each task. It worked, but it was clunky.
</p>

<p class="fade-in">
  GPT-3 introduced a radical alternative: <strong>just describe the task in the prompt</strong>. No fine-tuning. No gradient updates. No separate model. Just clever text formatting. The paper tested three settings:
</p>

<p class="fade-in">
  <strong>Zero-shot:</strong> Give the model only a task description. "Translate English to French: cheese ‚Üí"<br>
  <strong>One-shot:</strong> Give one example, then the query. "sea otter ‚Üí loutre de mer. cheese ‚Üí"<br>
  <strong>Few-shot:</strong> Give 10‚Äì100 examples, then the query.
</p>

<!-- DEMO 5: Prompting paradigm interactive -->
<div class="demo-container fade-in" id="demo-prompting">
  <h4>üß™ Demo: The Three Prompting Modes</h4>
  <p class="text-sm text-muted mb-sm">Click each mode to see how the prompt is constructed and how performance changes.</p>
  
  <div class="pill-row" style="justify-content:center;margin-bottom:16px;">
    <button class="btn btn-sm" id="prompt-mode-0" onclick="setPromptMode(0)" style="background:#fef2f2;color:#dc2626;border:2px solid #dc2626;">Zero-Shot</button>
    <button class="btn btn-sm" id="prompt-mode-1" onclick="setPromptMode(1)" style="background:white;color:#ea580c;border:2px solid #ea580c;">One-Shot</button>
    <button class="btn btn-sm" id="prompt-mode-2" onclick="setPromptMode(2)" style="background:white;color:#16a34a;border:2px solid #16a34a;">Few-Shot</button>
  </div>
  
  <div class="prompt-box" id="prompting-prompt-box" style="font-size:13px;min-height:150px;"></div>
  
  <div style="display:flex;justify-content:space-between;align-items:center;margin-top:14px;">
    <div>
      <span class="text-sm fw-700">Accuracy: </span>
      <span class="text-sm fw-700" id="prompting-accuracy" style="color:var(--accent);font-size:20px;">‚Äî</span>
    </div>
    <div>
      <span class="text-sm text-muted">Task: Sentiment Analysis (SST-2)</span>
    </div>
  </div>
  
  <div class="gauge-row" style="margin-top:8px;">
    <div class="gauge-label" style="min-width:80px;">Accuracy</div>
    <div class="gauge-track"><div class="gauge-fill" id="prompting-gauge" style="width:0;background:var(--accent);"></div></div>
    <div class="gauge-val" id="prompting-gauge-val">‚Äî</div>
  </div>
  
  <div class="demo-caption">Performance increases dramatically with just a few examples. Zero-shot already works surprisingly well.</div>
</div>

<p class="fade-in">
  The results were stunning. On many benchmarks, <strong>few-shot GPT-3 matched or exceeded fine-tuned models</strong> that had been specifically trained on thousands of labeled examples. On some tasks, even zero-shot GPT-3 was competitive. The field was shaken.
</p>

<p class="fade-in">
  This wasn't just a better technique ‚Äî it was a <strong>paradigm shift</strong>. Instead of "training" models for tasks, you could "prompt" them. Instead of datasets, you needed examples. Instead of ML engineers, you needed people who could write good instructions. The age of <strong>prompt engineering</strong> had begun.
</p>


<!-- ========== VI. IN-CONTEXT LEARNING ========== -->
<h2 class="section-title fade-in" id="sec-icl">
  <span class="section-num">VI. In-Context Learning</span>
  Learning Without Learning
</h2>

<p class="fade-in">
  The most mysterious aspect of GPT-3 is <strong>in-context learning</strong> (ICL). When you put examples in the prompt, the model doesn't update its weights. There's no backpropagation, no gradient descent, no parameter changes whatsoever. The model is frozen. And yet, it demonstrably <em>learns</em> the task.
</p>

<p class="fade-in">
  How? The leading theory is that <strong>the Transformer's attention mechanism implicitly implements a learning algorithm</strong>. When you place examples in the context, the attention layers identify the pattern ‚Äî "oh, the human wants me to translate English to French" ‚Äî and route information accordingly. It's as if the forward pass of the network <em>simulates</em> gradient descent.
</p>

<p class="fade-in">
  Think of it this way: during pre-training, GPT-3 saw billions of text sequences that contained implicit "tasks." A Wikipedia article about France contains implicit translation examples. A coding tutorial contains implicit code-generation examples. The model learned to <strong>recognize and execute task patterns</strong>, not just predict tokens.
</p>

<!-- DEMO 6: ICL step-through -->
<div class="demo-container fade-in" id="demo-icl">
  <h4>üß™ Demo: In-Context Learning Step by Step</h4>
  <p class="text-sm text-muted mb-sm">Step through the process of how attention routes information during in-context learning.</p>
  
  <div class="step-content" id="icl-step-content">
    <strong>Step 1:</strong> The prompt enters the model as a sequence of tokens. Examples and query are treated as one continuous text ‚Äî the model doesn't "know" which parts are examples and which is the query.
  </div>
  
  <div class="step-nav">
    <button class="btn btn-outline btn-sm" onclick="iclStep(-1)">‚Üê Prev</button>
    <span class="step-counter" id="icl-step-counter">Step 1 of 6</span>
    <button class="btn btn-primary btn-sm" onclick="iclStep(1)">Next ‚Üí</button>
  </div>
  
  <div style="margin-top:16px;">
    <svg width="100%" height="180" viewBox="0 0 600 180" id="icl-svg">
      <!-- tokens -->
      <rect x="10" y="120" width="70" height="30" rx="6" fill="#dbeafe" stroke="#2563eb" stroke-width="1.5"/>
      <text x="45" y="140" text-anchor="middle" font-size="10" font-weight="600" fill="#2563eb">sea otter</text>
      
      <rect x="90" y="120" width="12" height="30" rx="3" fill="#e5e5e5"/>
      <text x="96" y="140" text-anchor="middle" font-size="10" fill="#999">‚Üí</text>
      
      <rect x="112" y="120" width="100" height="30" rx="6" fill="#dcfce7" stroke="#16a34a" stroke-width="1.5"/>
      <text x="162" y="140" text-anchor="middle" font-size="10" font-weight="600" fill="#16a34a">loutre de mer</text>
      
      <rect x="225" y="120" width="60" height="30" rx="6" fill="#dbeafe" stroke="#2563eb" stroke-width="1.5"/>
      <text x="255" y="140" text-anchor="middle" font-size="10" font-weight="600" fill="#2563eb">cheese</text>
      
      <rect x="295" y="120" width="12" height="30" rx="3" fill="#e5e5e5"/>
      <text x="301" y="140" text-anchor="middle" font-size="10" fill="#999">‚Üí</text>
      
      <rect x="317" y="120" width="70" height="30" rx="6" fill="#dcfce7" stroke="#16a34a" stroke-width="1.5"/>
      <text x="352" y="140" text-anchor="middle" font-size="10" font-weight="600" fill="#16a34a">fromage</text>
      
      <rect x="400" y="120" width="65" height="30" rx="6" fill="#fef3c7" stroke="#d97706" stroke-width="1.5"/>
      <text x="432" y="140" text-anchor="middle" font-size="10" font-weight="600" fill="#92400e">plumber</text>
      
      <rect x="475" y="120" width="12" height="30" rx="3" fill="#e5e5e5"/>
      <text x="481" y="140" text-anchor="middle" font-size="10" fill="#999">‚Üí</text>
      
      <rect x="497" y="120" width="80" height="30" rx="6" fill="#fef3c7" stroke="#d97706" stroke-width="1.5" id="icl-output-box" opacity="0.3"/>
      <text x="537" y="140" text-anchor="middle" font-size="10" font-weight="600" fill="#92400e" id="icl-output-text" opacity="0.3">plombier</text>
      
      <!-- Attention arcs (hidden initially) -->
      <path d="M 432 120 Q 432 70 162 70 Q 162 70 162 120" stroke="#7c3aed" stroke-width="2" fill="none" opacity="0" id="icl-arc1" stroke-dasharray="4,4"/>
      <path d="M 432 120 Q 432 80 352 80 Q 352 80 352 120" stroke="#7c3aed" stroke-width="2" fill="none" opacity="0" id="icl-arc2" stroke-dasharray="4,4"/>
      <path d="M 432 120 Q 432 50 45 50 Q 45 50 45 120" stroke="#2563eb" stroke-width="1.5" fill="none" opacity="0" id="icl-arc3" stroke-dasharray="4,4"/>
      
      <!-- Attention label -->
      <text x="300" y="45" text-anchor="middle" font-size="11" font-weight="700" fill="#7c3aed" opacity="0" id="icl-attn-label">‚Üê Attention flows to examples ‚Üí</text>
    </svg>
  </div>
  
  <div class="demo-caption">No weights are updated. The model "learns" purely through attention patterns in the forward pass.</div>
</div>

<p class="fade-in">
  Recent research has formalized this intuition. Papers like "Transformers Learn In-Context by Gradient Descent" (von Oswald et al., 2023) showed that <strong>Transformer attention layers can implement mesa-optimization</strong> ‚Äî literally performing gradient descent steps inside the forward pass. The model is a learning algorithm pretending to be a prediction function.
</p>

<div class="callout fade-in">
  <p>üß† <strong>Mind-bending implication:</strong> GPT-3 doesn't just <em>contain</em> knowledge ‚Äî it contains a <em>learning algorithm</em>. The few-shot examples don't teach it facts; they activate a latent ability to recognize and solve a class of problems.</p>
</div>


<!-- ========== VII. TRAINING DATA ========== -->
<h2 class="section-title fade-in" id="sec-data">
  <span class="section-num">VII. The Training Data</span>
  Feeding the Beast
</h2>

<p class="fade-in">
  A 175-billion-parameter model is only as good as its training data. GPT-3 was trained on a massive, curated blend of internet text totaling roughly <strong>300 billion tokens</strong> (about 570 GB of text). But not all data is created equal ‚Äî the composition was carefully designed.
</p>

<p class="fade-in">
  The primary source was a <strong>filtered version of Common Crawl</strong>, a dataset of web pages scraped from the internet. But raw Common Crawl is noisy ‚Äî full of spam, boilerplate, and low-quality text. OpenAI trained a classifier (using high-quality text from Reddit as a positive signal) to filter Common Crawl down to a curated subset. This <strong>quality filtering</strong> was crucial.
</p>

<p class="fade-in">
  The remaining data came from more curated sources: <strong>WebText2</strong> (an expanded version of GPT-2's training set, based on Reddit-linked pages), two <strong>book corpora</strong> (Books1 and Books2), and <strong>English Wikipedia</strong>. Each source was weighted differently during training ‚Äî higher-quality sources were sampled more frequently.
</p>

<!-- DEMO 7: Data composition interactive -->
<div class="demo-container fade-in" id="demo-data">
  <h4>üß™ Demo: Training Data Composition</h4>
  <p class="text-sm text-muted mb-sm">Click each data source to explore its contribution. The pie shows token count, but sampling weights differ.</p>
  
  <div style="display:flex;gap:24px;flex-wrap:wrap;align-items:flex-start;">
    <div style="flex:1;min-width:220px;">
      <svg width="220" height="220" viewBox="0 0 220 220" id="data-pie">
        <!-- Pie slices drawn by JS -->
      </svg>
    </div>
    <div style="flex:1;min-width:260px;" id="data-details">
      <div class="text-sm fw-700 mb-sm" style="color:var(--accent);">Click a slice to learn more</div>
      <div id="data-info-box" class="step-content" style="font-size:14px;min-height:120px;">
        <strong>Common Crawl (filtered)</strong><br>
        410 billion tokens (before filtering to 180B used).<br>
        Filtered using a quality classifier trained on WebText as positive examples and raw Common Crawl as negatives. Roughly 60% of training tokens.<br>
        <span class="tag tag-blue">Sampling weight: 60%</span>
      </div>
    </div>
  </div>
  
  <table class="comp-table" style="margin-top:16px;">
    <thead>
      <tr><th>Source</th><th>Tokens (B)</th><th>Weight in Training</th><th>Epochs</th></tr>
    </thead>
    <tbody>
      <tr class="data-row" data-src="cc" style="cursor:pointer;" onclick="showDataInfo('cc')">
        <td><span style="color:#2563eb">‚óè</span> Common Crawl (filtered)</td><td>410</td><td>60%</td><td>0.44</td>
      </tr>
      <tr class="data-row" data-src="wt2" style="cursor:pointer;" onclick="showDataInfo('wt2')">
        <td><span style="color:#7c3aed">‚óè</span> WebText2</td><td>19</td><td>22%</td><td>2.9</td>
      </tr>
      <tr class="data-row" data-src="b1" style="cursor:pointer;" onclick="showDataInfo('b1')">
        <td><span style="color:#16a34a">‚óè</span> Books1</td><td>12</td><td>8%</td><td>1.9</td>
      </tr>
      <tr class="data-row" data-src="b2" style="cursor:pointer;" onclick="showDataInfo('b2')">
        <td><span style="color:#ea580c">‚óè</span> Books2</td><td>55</td><td>8%</td><td>0.43</td>
      </tr>
      <tr class="data-row" data-src="wiki" style="cursor:pointer;" onclick="showDataInfo('wiki')">
        <td><span style="color:#dc2626">‚óè</span> Wikipedia</td><td>3</td><td>3%</td><td>3.4</td>
      </tr>
    </tbody>
  </table>
  
  <div class="demo-caption">Higher-quality sources like Wikipedia are sampled multiple times (3.4 epochs), while Common Crawl sees less than half an epoch.</div>
</div>

<p class="fade-in">
  Notice something interesting in the table: Wikipedia, despite being tiny (3B tokens), was seen <strong>3.4 times</strong> during training. Common Crawl, with 410B tokens, was seen less than half an epoch (0.44√ó). This oversampling of quality data was a deliberate strategy ‚Äî the model needs to see reliable, well-structured text more often.
</p>

<p class="fade-in">
  The team also performed <strong>fuzzy deduplication</strong> to avoid the model memorizing repeated text, and they tried (imperfectly) to remove benchmark datasets from training to avoid contamination. This is a problem that would haunt the field for years to come.
</p>


<!-- ========== VIII. COMPUTE ========== -->
<h2 class="section-title fade-in" id="sec-compute">
  <span class="section-num">VIII. Compute &amp; Training</span>
  The $4.6 Million Model
</h2>

<p class="fade-in">
  Training GPT-3 required an <strong>staggering</strong> amount of compute: approximately <strong>3.14 √ó 10¬≤¬≥ floating-point operations</strong> (FLOPS). To put that in human terms: if you did one math operation per second, it would take you roughly <strong>10 quadrillion years</strong> ‚Äî about a million times the age of the universe.
</p>

<p class="fade-in">
  The training was done on a cluster of <strong>thousands of NVIDIA V100 GPUs</strong>, using a mix of model parallelism and data parallelism. Estimates place the training cost at approximately <strong>$4.6 million</strong> in cloud compute ‚Äî a figure that seems quaint now but was jaw-dropping in 2020.
</p>

<p class="fade-in">
  The model was trained using the <strong>Adam optimizer</strong> with a cosine learning rate schedule, a batch size of 3.2 million tokens, and a sequence length of 2,048. Training took several weeks. The paper doesn't disclose exactly how long (OpenAI was already becoming more secretive), but estimates suggest it took <strong>~34 days</strong> on a cluster of ~10,000 V100 GPUs.
</p>

<!-- DEMO 8: Compute calculator -->
<div class="demo-container fade-in" id="demo-compute">
  <h4>üß™ Demo: Compute Cost Estimator</h4>
  <p class="text-sm text-muted mb-sm">Adjust GPU count and training days to see how compute scales. The target is 3.14 √ó 10¬≤¬≥ FLOPS.</p>
  
  <div style="display:flex;gap:20px;flex-wrap:wrap;">
    <div style="flex:1;min-width:200px;">
      <label class="text-sm fw-700">GPU Type:</label>
      <select id="gpu-select" onchange="updateComputeCalc()" style="width:100%;font-family:system-ui,sans-serif;font-size:14px;padding:8px;border-radius:8px;border:1px solid #ddd;margin-top:4px;">
        <option value="125">V100 (125 TFLOPS FP16)</option>
        <option value="312">A100 (312 TFLOPS FP16)</option>
        <option value="990">H100 (990 TFLOPS FP16)</option>
      </select>
    </div>
    <div style="flex:1;min-width:200px;">
      <label class="text-sm fw-700">Number of GPUs: <span id="gpu-count-label">10,000</span></label>
      <input type="range" id="gpu-count" min="1000" max="30000" step="1000" value="10000" oninput="updateComputeCalc()">
    </div>
  </div>
  
  <div style="display:flex;gap:20px;flex-wrap:wrap;margin-top:12px;">
    <div style="flex:1;min-width:200px;">
      <label class="text-sm fw-700">Utilization: <span id="util-label">30%</span></label>
      <input type="range" id="util-slider" min="10" max="60" step="5" value="30" oninput="updateComputeCalc()">
    </div>
  </div>
  
  <div style="margin-top:20px;padding:16px;background:#f9fafb;border-radius:10px;">
    <div style="display:flex;justify-content:space-between;flex-wrap:wrap;gap:12px;">
      <div class="text-center" style="flex:1;">
        <div class="text-sm text-muted">Training Time</div>
        <div class="fw-700" style="font-size:24px;font-family:system-ui,sans-serif;" id="compute-days">34 days</div>
      </div>
      <div class="text-center" style="flex:1;">
        <div class="text-sm text-muted">Estimated Cost</div>
        <div class="fw-700" style="font-size:24px;font-family:system-ui,sans-serif;color:var(--accent);" id="compute-cost">$4.6M</div>
      </div>
      <div class="text-center" style="flex:1;">
        <div class="text-sm text-muted">FLOPS Achieved</div>
        <div class="fw-700" style="font-size:18px;font-family:system-ui,sans-serif;" id="compute-flops">3.14 √ó 10¬≤¬≥</div>
      </div>
    </div>
  </div>
  
  <div class="gauge-row" style="margin-top:12px;">
    <div class="gauge-label" style="min-width:100px;">Target FLOPS</div>
    <div class="gauge-track"><div class="gauge-fill" id="compute-gauge" style="width:100%;background:var(--green);"></div></div>
    <div class="gauge-val" id="compute-gauge-val">100%</div>
  </div>
  
  <div class="demo-caption">Real-world GPU utilization is typically 30‚Äì50%. Higher utilization means faster training but requires expert engineering.</div>
</div>

<p class="fade-in">
  This compute requirement created an immediate <strong>accessibility problem</strong>. Only a handful of organizations in the world could afford to train a model like GPT-3. This concentration of AI capability in a few well-funded labs would become one of the most debated issues in the field.
</p>

<div class="callout fade-in">
  <p>‚ö° <strong>Fun fact:</strong> GPT-3's training consumed roughly 1,287 MWh of electricity ‚Äî enough to power about 120 average US homes for an entire year. The carbon footprint was estimated at ~552 tonnes of CO‚ÇÇ, equivalent to driving a car 1.4 million miles.</p>
</div>


<!-- ========== IX. BENCHMARKS ========== -->
<h2 class="section-title fade-in" id="sec-benchmarks">
  <span class="section-num">IX. Benchmark Results</span>
  The Scoreboard
</h2>

<p class="fade-in">
  The GPT-3 paper is <em>exhaustive</em>. It evaluates the model on over <strong>40 benchmarks</strong> spanning language understanding, question answering, translation, arithmetic, commonsense reasoning, reading comprehension, and more. The breadth alone was unprecedented ‚Äî most papers tested on 5‚Äì10 benchmarks.
</p>

<p class="fade-in">
  The headline results: GPT-3 few-shot achieved <strong>state-of-the-art on several benchmarks</strong> without any fine-tuning, and was competitive with fine-tuned models on many others. The most dramatic results came on tasks requiring <strong>common sense and world knowledge</strong> ‚Äî areas where the model's vast training data gave it an edge.
</p>

<p class="fade-in">
  But GPT-3 wasn't perfect. It struggled with tasks requiring <strong>precise reasoning</strong>, <strong>mathematical computation</strong>, and <strong>structured output</strong>. On the challenging WinoGrande commonsense benchmark, GPT-3 few-shot hit 77.7% (vs. fine-tuned SOTA of 84.6%). On SuperGLUE, it scored 71.8 few-shot vs. fine-tuned T5's 89.3. A clear gap remained.
</p>

<!-- DEMO 9: Benchmark explorer -->
<div class="demo-container fade-in" id="demo-benchmarks">
  <h4>üß™ Demo: Benchmark Results Explorer</h4>
  <p class="text-sm text-muted mb-sm">Select a category to see GPT-3's scores compared to fine-tuned SOTA at the time.</p>
  
  <div class="pill-row" style="margin-bottom:16px;">
    <button class="btn btn-sm btn-outline" onclick="showBenchCategory('qa')">Question Answering</button>
    <button class="btn btn-sm btn-outline" onclick="showBenchCategory('cls')">Classification</button>
    <button class="btn btn-sm btn-outline" onclick="showBenchCategory('reason')">Reasoning</button>
    <button class="btn btn-sm btn-outline" onclick="showBenchCategory('gen')">Generation</button>
  </div>
  
  <div id="bench-display">
    <div class="bar-chart" id="bench-bars"></div>
  </div>
  
  <div style="margin-top:14px;display:flex;gap:16px;font-family:system-ui,sans-serif;font-size:12px;justify-content:center;">
    <span><span style="display:inline-block;width:12px;height:12px;border-radius:3px;background:var(--accent);vertical-align:middle;margin-right:4px;"></span>GPT-3 Few-Shot</span>
    <span><span style="display:inline-block;width:12px;height:12px;border-radius:3px;background:#94a3b8;vertical-align:middle;margin-right:4px;"></span>Fine-tuned SOTA</span>
  </div>
  
  <div class="demo-caption">GPT-3 without fine-tuning often rivals models specifically trained for each task. But gaps remain on tasks requiring precise reasoning.</div>
</div>

<p class="fade-in">
  Perhaps the most remarkable results were in <strong>tasks the model was never explicitly trained for</strong>. GPT-3 could perform 2-digit arithmetic (100% accuracy on addition, ~98% on subtraction), unscramble words, use novel words after seeing a definition, and even generate plausible news articles that human evaluators struggled to distinguish from real ones.
</p>

<p class="fade-in">
  The news article generation result was particularly alarming: human accuracy at detecting GPT-3-generated news was barely above chance (<strong>~52%</strong>). This would become a recurring theme in the societal impacts discussion.
</p>


<!-- ========== X. LIMITATIONS ========== -->
<h2 class="section-title fade-in" id="sec-limitations">
  <span class="section-num">X. Limitations &amp; Failure Modes</span>
  Where the Giant Stumbles
</h2>

<p class="fade-in">
  The GPT-3 paper deserves credit for an unusually honest <strong>limitations section</strong>. The authors identified several categories of failure that would define the challenges of large language models for years to come.
</p>

<p class="fade-in">
  <strong>Repetition:</strong> GPT-3 sometimes gets stuck in loops, repeating phrases or sentences. At longer generation lengths, it can lose coherence and circle back to earlier themes. The autoregressive nature means errors compound ‚Äî one bad token can derail the rest.
</p>

<p class="fade-in">
  <strong>Factual errors (hallucinations):</strong> The model confidently states incorrect information. It might invent plausible-sounding historical events, misattribute quotes, or confuse similar entities. It has no mechanism to verify claims against external reality.
</p>

<p class="fade-in">
  <strong>Reasoning failures:</strong> While GPT-3 can do simple arithmetic, it breaks down on multi-step reasoning, especially when the problem requires keeping track of intermediate state. Long logical chains are its kryptonite.
</p>

<p class="fade-in">
  <strong>Bias:</strong> Trained on internet text, GPT-3 inevitably absorbed the biases present in its training data ‚Äî gender stereotypes, racial prejudice, religious bias, and more. The paper specifically studied gender bias in occupations and found significant correlations.
</p>

<!-- DEMO 10: Limitation explorer -->
<div class="demo-container fade-in" id="demo-limitations">
  <h4>üß™ Demo: Failure Mode Explorer</h4>
  <p class="text-sm text-muted mb-sm">Click each failure mode to see an example and explanation.</p>
  
  <div class="icon-grid" id="limitation-grid">
    <div class="icon-card" onclick="showLimitation('repeat')">
      <div class="icon-emoji">üîÅ</div>
      <div class="icon-label">Repetition</div>
    </div>
    <div class="icon-card" onclick="showLimitation('hallucination')">
      <div class="icon-emoji">üåÄ</div>
      <div class="icon-label">Hallucination</div>
    </div>
    <div class="icon-card" onclick="showLimitation('reasoning')">
      <div class="icon-emoji">üßÆ</div>
      <div class="icon-label">Reasoning</div>
    </div>
    <div class="icon-card" onclick="showLimitation('bias')">
      <div class="icon-emoji">‚öñÔ∏è</div>
      <div class="icon-label">Bias</div>
    </div>
    <div class="icon-card" onclick="showLimitation('context')">
      <div class="icon-emoji">üìè</div>
      <div class="icon-label">Limited Context</div>
    </div>
    <div class="icon-card" onclick="showLimitation('update')">
      <div class="icon-emoji">üìÖ</div>
      <div class="icon-label">Stale Knowledge</div>
    </div>
  </div>
  
  <div id="limitation-detail" class="step-content" style="margin-top:12px;font-size:15px;">
    <strong>Click a card above</strong> to explore each failure mode with examples.
  </div>
  
  <div class="demo-caption">Many of these limitations persist in today's models, though mitigations have improved significantly.</div>
</div>

<div class="callout fade-in">
  <p>‚ö†Ô∏è <strong>On bias:</strong> The paper found that GPT-3 associated "male" with competence-related terms and "female" with appearance-related terms. For religion, it disproportionately associated Islam with violence. These biases reflected internet training data, but the model amplified and systematized them.</p>
</div>


<!-- ========== XI. SOCIETAL IMPLICATIONS ========== -->
<h2 class="section-title fade-in" id="sec-societal">
  <span class="section-num">XI. Societal Implications</span>
  The AI Era Begins
</h2>

<p class="fade-in">
  GPT-3 wasn't just a research milestone ‚Äî it was a <strong>cultural inflection point</strong>. When OpenAI released the API in June 2020, thousands of developers got access to a model that could write essays, code, poetry, business emails, and more. The demos went viral. Twitter was flooded with examples. People were equal parts amazed and terrified.
</p>

<p class="fade-in">
  The implications were sweeping. <strong>Misinformation</strong> became cheaper to produce at scale. <strong>Education</strong> faced questions about AI-generated assignments. <strong>Creative industries</strong> wondered about the future of human writing. <strong>Employment</strong> debates intensified ‚Äî if a model could draft legal contracts, what happened to paralegals?
</p>

<p class="fade-in">
  The paper itself devoted significant space to these concerns, discussing <strong>potential misuse</strong> (spam, phishing, propaganda), <strong>fairness and bias</strong>, and <strong>energy consumption</strong>. The authors acknowledged that releasing such a powerful model created risks they couldn't fully anticipate. This tension between open science and responsible deployment would become the defining ethical question of the AI era.
</p>

<!-- DEMO 11: Timeline of impact -->
<div class="demo-container fade-in" id="demo-societal">
  <h4>üß™ Demo: GPT-3's Ripple Effects</h4>
  <p class="text-sm text-muted mb-sm">Scroll through the timeline to see how GPT-3 triggered a cascade of developments.</p>
  
  <div class="hscroll" id="timeline-scroll">
    <div class="hscroll-card" style="border-left:3px solid var(--accent);">
      <h5>May 2020</h5>
      <p>Paper released on arXiv. Researchers stunned by few-shot results. "Scale is all you need" debates begin.</p>
    </div>
    <div class="hscroll-card" style="border-left:3px solid var(--purple);">
      <h5>June 2020</h5>
      <p>OpenAI launches GPT-3 API beta. Viral demos flood Twitter. "AI summer" begins.</p>
    </div>
    <div class="hscroll-card" style="border-left:3px solid var(--green);">
      <h5>Aug 2020</h5>
      <p>The Guardian publishes an article "written by GPT-3." Debate about AI authorship ignites.</p>
    </div>
    <div class="hscroll-card" style="border-left:3px solid var(--orange);">
      <h5>2020‚Äì2021</h5>
      <p>Hundreds of startups build on the GPT-3 API. Copy.ai, Jasper, and others launch. "Prompt engineering" becomes a job title.</p>
    </div>
    <div class="hscroll-card" style="border-left:3px solid var(--red);">
      <h5>2021</h5>
      <p>Google Brain releases a 540B model (PaLM). The race to scale accelerates. Chinchilla questions "bigger = better."</p>
    </div>
    <div class="hscroll-card" style="border-left:3px solid #2563eb;">
      <h5>Late 2022</h5>
      <p>ChatGPT launches (based on GPT-3.5). Reaches 100M users in 2 months. The AI revolution goes mainstream.</p>
    </div>
    <div class="hscroll-card" style="border-left:3px solid #7c3aed;">
      <h5>2023‚Äì2024</h5>
      <p>GPT-4, Claude, Gemini, Llama. Every major tech company has a large language model. GPT-3 was the spark.</p>
    </div>
    <div class="hscroll-card" style="border-left:3px solid #16a34a;">
      <h5>2025+</h5>
      <p>AI regulation emerges worldwide. The questions GPT-3 raised ‚Äî about bias, jobs, truth ‚Äî remain central.</p>
    </div>
  </div>
  
  <div style="margin-top:16px;">
    <p class="text-sm fw-700 mb-sm" style="color:var(--accent);">Quick Poll: What's GPT-3's biggest societal impact?</p>
    <div id="societal-poll">
      <button class="quiz-option" onclick="votePoll(this, 0)">üî¨ Accelerated AI research (the race to scale)</button>
      <button class="quiz-option" onclick="votePoll(this, 1)">üíº Disrupted knowledge-worker jobs</button>
      <button class="quiz-option" onclick="votePoll(this, 2)">üì∞ Enabled cheap misinformation at scale</button>
      <button class="quiz-option" onclick="votePoll(this, 3)">üé® Democratized creative tools</button>
    </div>
    <div id="poll-results" style="display:none;margin-top:12px;">
      <div class="gauge-row"><div class="gauge-label" style="min-width:180px;font-size:13px;">AI Research</div><div class="gauge-track"><div class="gauge-fill" id="poll-0" style="width:0;background:var(--accent);"></div></div><div class="gauge-val" id="poll-v0">0</div></div>
      <div class="gauge-row"><div class="gauge-label" style="min-width:180px;font-size:13px;">Job Disruption</div><div class="gauge-track"><div class="gauge-fill" id="poll-1" style="width:0;background:var(--orange);"></div></div><div class="gauge-val" id="poll-v1">0</div></div>
      <div class="gauge-row"><div class="gauge-label" style="min-width:180px;font-size:13px;">Misinformation</div><div class="gauge-track"><div class="gauge-fill" id="poll-2" style="width:0;background:var(--red);"></div></div><div class="gauge-val" id="poll-v2">0</div></div>
      <div class="gauge-row"><div class="gauge-label" style="min-width:180px;font-size:13px;">Creative Tools</div><div class="gauge-track"><div class="gauge-fill" id="poll-3" style="width:0;background:var(--green);"></div></div><div class="gauge-val" id="poll-v3">0</div></div>
    </div>
  </div>
  
  <div class="demo-caption">GPT-3 didn't just change AI ‚Äî it changed the conversation about what AI means for society.</div>
</div>

<p class="fade-in">
  Looking back from 2026, GPT-3 was the opening act. It proved three things that changed the trajectory of technology: (1) scale works, (2) prompting can replace fine-tuning, and (3) language models are general-purpose reasoning engines, not just text generators. Every model that came after ‚Äî GPT-4, Claude, Gemini, Llama ‚Äî stood on GPT-3's shoulders.
</p>


<!-- ========== XII. SUMMARY ========== -->
<h2 class="section-title fade-in" id="sec-summary">
  <span class="section-num">XII. Summary &amp; Legacy</span>
  What GPT-3 Taught Us
</h2>

<p class="fade-in">
  Let's distill the key lessons from this landmark paper:
</p>

<div class="summary-grid fade-in">
  <div class="summary-card">
    <h4>üèóÔ∏è Architecture</h4>
    <p>Decoder-only Transformer with 96 layers, 175B parameters. Simplicity at scale beats complexity at small scale.</p>
  </div>
  <div class="summary-card">
    <h4>üìà Scale</h4>
    <p>100√ó more parameters than GPT-2. Emergent abilities appear at sufficient scale ‚Äî abilities absent in smaller models.</p>
  </div>
  <div class="summary-card">
    <h4>üéØ Prompting</h4>
    <p>Zero-shot, one-shot, and few-shot prompting replace fine-tuning. Task specification moves from training to inference.</p>
  </div>
  <div class="summary-card">
    <h4>üß† In-Context Learning</h4>
    <p>No gradient updates. The model "learns" from examples in the prompt through attention patterns alone.</p>
  </div>
  <div class="summary-card">
    <h4>üìö Data</h4>
    <p>300B tokens from filtered Common Crawl, WebText2, books, and Wikipedia. Quality filtering was crucial.</p>
  </div>
  <div class="summary-card">
    <h4>üí∞ Compute</h4>
    <p>~$4.6M training cost, ~3.14 √ó 10¬≤¬≥ FLOPS. AI capability became a function of funding.</p>
  </div>
  <div class="summary-card">
    <h4>üìä Results</h4>
    <p>SOTA on several benchmarks without fine-tuning. Competitive across 40+ tasks. Humans couldn't detect its writing.</p>
  </div>
  <div class="summary-card">
    <h4>‚ö†Ô∏è Limitations</h4>
    <p>Bias, hallucination, repetition, limited context, stale knowledge. Honest about what doesn't work.</p>
  </div>
</div>

<p class="fade-in">
  GPT-3 was both a scientific achievement and a societal event. It demonstrated that <strong>scale can substitute for specialization</strong> ‚Äî that a single, massive model trained on diverse text can perform an enormous range of tasks without modification. This insight, more than any specific benchmark number, is what made the paper revolutionary.
</p>

<p class="fade-in">
  The paper's legacy extends far beyond its own results. It catalyzed the <strong>large language model revolution</strong>, inspired the development of ChatGPT (which brought AI to the masses), and fundamentally changed how we think about artificial intelligence. Before GPT-3, AI was a collection of specialist tools. After GPT-3, it was a <strong>general-purpose technology</strong>.
</p>

<p class="fade-in">
  Whether that's exciting or terrifying ‚Äî or both ‚Äî is a question we're still answering.
</p>

<div class="callout blue fade-in">
  <p>üìñ <strong>Read the full paper:</strong> <a href="https://arxiv.org/abs/2005.14165" target="_blank">arXiv:2005.14165</a> ‚Äî "Language Models are Few-Shot Learners" by Tom Brown, Benjamin Mann, Nick Ryder, et al. (2020). 75 pages. Worth every one.</p>
</div>

<!-- Further Resources -->
<h3 class="fade-in" style="margin-top:60px;">Further Resources</h3>
<ul class="fade-in" style="margin-bottom:40px;">
  <li><a href="https://arxiv.org/abs/2005.14165" target="_blank">GPT-3 Paper (arXiv)</a> ‚Äî The original 75-page paper</li>
  <li><a href="https://arxiv.org/abs/2001.08361" target="_blank">Scaling Laws for Neural LMs</a> ‚Äî Kaplan et al., the theoretical foundation</li>
  <li><a href="https://arxiv.org/abs/2203.15556" target="_blank">Emergent Abilities of Large LMs</a> ‚Äî Wei et al., formalizing what GPT-3 demonstrated</li>
  <li><a href="https://arxiv.org/abs/1706.03762" target="_blank">Attention Is All You Need</a> ‚Äî Vaswani et al., the Transformer architecture</li>
  <li><a href="https://jalammar.github.io/illustrated-gpt2/" target="_blank">The Illustrated GPT-2</a> ‚Äî Jay Alammar's visual guide (applies to GPT-3's architecture)</li>
  <li><a href="https://arxiv.org/abs/2211.15661" target="_blank">Are Emergent Abilities a Mirage?</a> ‚Äî Schaeffer et al., the counterargument</li>
</ul>

</article>

<!-- ========== FOOTER ========== -->
<footer>
  <p>Built with care. Inspired by <a href="https://explainers.blog">explainers.blog</a>.</p>
  <p style="margin-top:6px;">Paper: "Language Models are Few-Shot Learners" ‚Äî Brown et al., 2020</p>
</footer>

<!-- ========== JAVASCRIPT ========== -->
<script>
// ========== Scroll animations ==========
const observer = new IntersectionObserver((entries) => {
  entries.forEach(e => { if (e.isIntersecting) e.target.classList.add('visible'); });
}, { threshold: 0.1 });
document.querySelectorAll('.fade-in').forEach(el => observer.observe(el));

// ========== DEMO 1: Opening few-shot ==========
function runOpeningDemo() {
  const sel = document.getElementById('opening-select').value.split('|');
  document.getElementById('opening-input-word').textContent = sel[0];
  const comp = document.getElementById('opening-completion');
  const cursor = document.getElementById('opening-cursor');
  comp.textContent = '';
  comp.classList.remove('visible');
  cursor.style.display = 'inline-block';
  
  const word = sel[1];
  let i = 0;
  const interval = setInterval(() => {
    if (i < word.length) {
      comp.textContent += word[i];
      comp.classList.add('visible');
      i++;
    } else {
      clearInterval(interval);
      cursor.style.display = 'none';
    }
  }, 80);
}

// ========== DEMO 2: Scale slider ==========
const scaleData = [
  { name: '125M', abilities: ['Autocomplete', 'Grammar'], desc: '<strong>GPT-3 Small (125M):</strong> Basic grammar and sentence completion. Can finish a sentence you start. Struggles with facts and logic. Think of it as a very fast autocomplete.', color: '#94a3b8' },
  { name: '350M', abilities: ['Autocomplete', 'Grammar', 'Simple Q&A'], desc: '<strong>GPT-3 Medium (350M):</strong> Can answer simple factual questions and produce more coherent paragraphs. Still gets confused by multi-step reasoning.', color: '#64748b' },
  { name: '1.3B', abilities: ['Autocomplete', 'Grammar', 'Q&A', 'Basic Translation'], desc: '<strong>GPT-3 1.3B:</strong> Translation ability emerges. Can handle simple English‚ÜíFrench with examples. Starts showing few-shot ability on classification tasks.', color: '#7c3aed' },
  { name: '6.7B', abilities: ['Autocomplete', 'Grammar', 'Q&A', 'Translation', 'Arithmetic', 'Summarization'], desc: '<strong>GPT-3 6.7B:</strong> Arithmetic emerges (2-digit addition). Can summarize articles. Few-shot learning becomes reliable across many tasks.', color: '#ea580c' },
  { name: '13B', abilities: ['Autocomplete', 'Grammar', 'Q&A', 'Translation', 'Arithmetic', 'Summarization', 'Analogies', 'Code'], desc: '<strong>GPT-3 13B:</strong> Analogy solving and basic code generation appear. Performance on reasoning benchmarks jumps. Starting to look "smart."', color: '#16a34a' },
  { name: '175B', abilities: ['Autocomplete', 'Grammar', 'Q&A', 'Translation', 'Arithmetic', 'Summarization', 'Analogies', 'Code', 'Creative Writing', 'Logic', 'Few-Shot Everything'], desc: '<strong>GPT-3 Full (175B):</strong> The full model. Creative writing, multi-step reasoning, novel task generalization, code generation, article writing indistinguishable from human. The "everything model."', color: '#2563eb' }
];

function updateScaleDemo() {
  const v = parseInt(document.getElementById('scale-slider').value);
  const d = scaleData[v];
  document.getElementById('scale-number').textContent = d.name;
  document.getElementById('scale-number').style.color = d.color;
  document.getElementById('scale-desc').innerHTML = d.desc;
  
  const pills = document.getElementById('scale-pills');
  pills.innerHTML = '';
  const colors = ['tag-blue','tag-purple','tag-green','tag-orange','tag-red'];
  d.abilities.forEach((a, i) => {
    const span = document.createElement('span');
    span.className = 'tag ' + colors[i % colors.length];
    span.textContent = a;
    span.style.transition = 'all 0.3s';
    span.style.opacity = '0';
    pills.appendChild(span);
    setTimeout(() => { span.style.opacity = '1'; }, i * 60);
  });
}
updateScaleDemo();

// ========== DEMO 3: Architecture ==========
(function initArch() {
  const stack = document.getElementById('layer-stack-viz');
  for (let i = 0; i < 96; i++) {
    const div = document.createElement('div');
    div.className = 'layer-block';
    const hue = Math.floor((i / 96) * 60 + 220); // blue ‚Üí purple
    const sat = 60 + Math.floor((i / 96) * 20);
    div.style.background = `hsl(${hue}, ${sat}%, 65%)`;
    const tooltip = document.createElement('span');
    tooltip.className = 'layer-tooltip';
    const layerType = i < 32 ? 'Syntax & Grammar' : i < 64 ? 'Semantics & Facts' : 'Reasoning & Planning';
    tooltip.textContent = `Layer ${i + 1}: ${layerType}`;
    div.appendChild(tooltip);
    stack.appendChild(div);
  }
})();

document.querySelectorAll('.arch-clickable').forEach(el => {
  el.style.cursor = 'pointer';
  el.addEventListener('click', () => {
    const info = el.getAttribute('data-info');
    const box = document.getElementById('arch-info');
    if (info === 'attn') {
      box.innerHTML = '<strong>Multi-Head Self-Attention</strong> (96 heads): Each head computes attention weights across all previous tokens. With 96 heads and d=12,288, each head operates on a 128-dimensional subspace. The causal mask ensures tokens only attend to previous positions. This is where in-context learning happens ‚Äî attention patterns route information from examples to the query.';
    } else {
      box.innerHTML = '<strong>Feed-Forward Network</strong> (4√ó expansion): A two-layer MLP that expands the 12,288-dim representation to 49,152 dimensions (4√ó), applies GELU activation, then projects back. This is where most of the model\'s "knowledge" is stored ‚Äî factual associations, linguistic patterns, and learned heuristics live in these weight matrices.';
    }
  });
});

// ========== DEMO 4: Parameter bars ==========
let logScale = false;
const paramValues = { elmo: 94, gpt1: 117, bert: 340, gpt2: 1500, t5: 11000, gpt3: 175000 };

function animateParamBars() {
  const max = logScale ? Math.log10(175000) : 175000;
  Object.entries(paramValues).forEach(([key, val]) => {
    const pct = logScale ? (Math.log10(val) / max * 100) : (val / max * 100);
    document.getElementById('bar-' + key).style.width = pct + '%';
  });
}

function toggleLogScale() {
  logScale = !logScale;
  document.getElementById('log-toggle').textContent = logScale ? 'Switch to Linear' : 'Switch to Log Scale';
  animateParamBars();
}

// ========== DEMO 5: Prompting modes ==========
const promptModes = [
  {
    prompt: '<span class="prompt-label">Task: </span><span class="prompt-text">Determine the sentiment of the following review.</span>\n\n<span class="prompt-label">Review: </span><span class="prompt-text">"This movie was absolutely wonderful and I loved every minute."</span>\n<span class="prompt-label">Sentiment: </span><span class="prompt-completion visible">Positive</span>',
    accuracy: '79.4%',
    pct: 79.4,
    label: 'Zero-Shot'
  },
  {
    prompt: '<span class="prompt-label">Task: </span><span class="prompt-text">Determine the sentiment of the following review.</span>\n\n<span class="prompt-label">Review: </span><span class="prompt-text">"The food was cold and the service was terrible."</span>\n<span class="prompt-label">Sentiment: </span><span class="prompt-text">Negative</span>\n\n<span class="prompt-label">Review: </span><span class="prompt-text">"This movie was absolutely wonderful and I loved every minute."</span>\n<span class="prompt-label">Sentiment: </span><span class="prompt-completion visible">Positive</span>',
    accuracy: '88.1%',
    pct: 88.1,
    label: 'One-Shot'
  },
  {
    prompt: '<span class="prompt-label">Task: </span><span class="prompt-text">Determine the sentiment of the following review.</span>\n\n<span class="prompt-label">Review: </span><span class="prompt-text">"The food was cold and the service was terrible."</span>\n<span class="prompt-label">Sentiment: </span><span class="prompt-text">Negative</span>\n\n<span class="prompt-label">Review: </span><span class="prompt-text">"A brilliant and heartwarming story."</span>\n<span class="prompt-label">Sentiment: </span><span class="prompt-text">Positive</span>\n\n<span class="prompt-label">Review: </span><span class="prompt-text">"Boring plot, bad acting. Skip it."</span>\n<span class="prompt-label">Sentiment: </span><span class="prompt-text">Negative</span>\n\n<span class="prompt-label">Review: </span><span class="prompt-text">"This movie was absolutely wonderful and I loved every minute."</span>\n<span class="prompt-label">Sentiment: </span><span class="prompt-completion visible">Positive</span>',
    accuracy: '95.3%',
    pct: 95.3,
    label: 'Few-Shot'
  }
];

function setPromptMode(mode) {
  const d = promptModes[mode];
  document.getElementById('prompting-prompt-box').innerHTML = d.prompt.replace(/\n/g, '<br>');
  document.getElementById('prompting-accuracy').textContent = d.accuracy;
  document.getElementById('prompting-gauge').style.width = d.pct + '%';
  document.getElementById('prompting-gauge-val').textContent = d.accuracy;
  
  const colors = ['#dc2626', '#ea580c', '#16a34a'];
  document.getElementById('prompting-gauge').style.background = colors[mode];
  
  [0,1,2].forEach(i => {
    const btn = document.getElementById('prompt-mode-' + i);
    btn.style.background = i === mode ? (i === 0 ? '#fef2f2' : i === 1 ? '#ffedd5' : '#dcfce7') : 'white';
    btn.style.fontWeight = i === mode ? '800' : '600';
  });
}
setPromptMode(0);

// ========== DEMO 6: ICL step-through ==========
let iclCurrentStep = 0;
const iclSteps = [
  {
    text: '<strong>Step 1 ‚Äî Tokenization:</strong> The prompt enters the model as a sequence of tokens. Examples and query are treated as one continuous text ‚Äî the model doesn\'t "know" which parts are examples and which is the query.',
    arcs: [false, false, false],
    label: false,
    output: false
  },
  {
    text: '<strong>Step 2 ‚Äî Embedding:</strong> Each token is mapped to a 12,288-dimensional vector, combined with positional encodings. The examples and query live in the same high-dimensional space.',
    arcs: [false, false, false],
    label: false,
    output: false
  },
  {
    text: '<strong>Step 3 ‚Äî Attention to examples:</strong> When processing the query token "plumber", attention heads look back at all previous tokens. Some heads specialize in finding <em>structural parallels</em> ‚Äî they notice that English words are followed by "‚Üí" and then French words.',
    arcs: [true, true, false],
    label: true,
    output: false
  },
  {
    text: '<strong>Step 4 ‚Äî Pattern extraction:</strong> Other attention heads extract the <em>content</em> of the pattern. They attend to "sea otter ‚Üí loutre de mer" and "cheese ‚Üí fromage", learning the English‚ÜíFrench mapping from the key-value structure of attention.',
    arcs: [true, true, true],
    label: true,
    output: false
  },
  {
    text: '<strong>Step 5 ‚Äî Composition:</strong> Through 96 layers of processing, the model composes the structural pattern (X ‚Üí translation of X) with the query content (plumber), gradually building a representation that encodes "the French word for plumber."',
    arcs: [true, true, true],
    label: true,
    output: false
  },
  {
    text: '<strong>Step 6 ‚Äî Prediction:</strong> The final layer\'s representation is projected to the vocabulary, and the softmax selects "plombier" as the highest-probability next token. <em>No weights were changed.</em> The entire "learning" happened through attention routing.',
    arcs: [false, false, false],
    label: false,
    output: true
  }
];

function iclStep(dir) {
  iclCurrentStep = Math.max(0, Math.min(iclSteps.length - 1, iclCurrentStep + dir));
  const s = iclSteps[iclCurrentStep];
  document.getElementById('icl-step-content').innerHTML = s.text;
  document.getElementById('icl-step-counter').textContent = `Step ${iclCurrentStep + 1} of ${iclSteps.length}`;
  
  document.getElementById('icl-arc1').style.opacity = s.arcs[0] ? '0.7' : '0';
  document.getElementById('icl-arc2').style.opacity = s.arcs[1] ? '0.7' : '0';
  document.getElementById('icl-arc3').style.opacity = s.arcs[2] ? '0.5' : '0';
  document.getElementById('icl-attn-label').style.opacity = s.label ? '1' : '0';
  document.getElementById('icl-output-box').style.opacity = s.output ? '1' : '0.3';
  document.getElementById('icl-output-text').style.opacity = s.output ? '1' : '0.3';
}

// ========== DEMO 7: Data composition ==========
const dataInfo = {
  cc: { title: 'Common Crawl (filtered)', text: '410 billion tokens (before filtering to ~180B used). Filtered using a quality classifier trained on WebText as positive examples and raw Common Crawl as negatives. This classifier used logistic regression on n-gram features ‚Äî simple but effective. Roughly 60% of training mix.', tag: 'Sampling weight: 60%', color: 'tag-blue' },
  wt2: { title: 'WebText2', text: '19 billion tokens. An expanded version of GPT-2\'s training set. Contains web pages linked from Reddit with ‚â•3 karma ‚Äî a proxy for quality. Higher quality than Common Crawl but much smaller. Oversampled at 22% of training.', tag: 'Sampling weight: 22%', color: 'tag-purple' },
  b1: { title: 'Books1', text: '12 billion tokens. A large corpus of books (likely from Project Gutenberg or similar). Provides long-form, well-structured narrative text. Helps the model learn coherent long-range dependencies.', tag: 'Sampling weight: 8%', color: 'tag-green' },
  b2: { title: 'Books2', text: '55 billion tokens. A second, larger book corpus (likely a commercial/proprietary source). Combined with Books1, provides 67B tokens of high-quality book text. Books teach the model about dialogue, narrative, and exposition.', tag: 'Sampling weight: 8%', color: 'tag-orange' },
  wiki: { title: 'Wikipedia', text: '3 billion tokens. English Wikipedia only. The gold standard of factual, well-structured text. Despite its small size, it\'s seen 3.4 times during training ‚Äî the highest epoch count of any source. Critical for factual knowledge.', tag: 'Sampling weight: 3%', color: 'tag-red' }
};

function showDataInfo(src) {
  const d = dataInfo[src];
  document.getElementById('data-info-box').innerHTML = `<strong>${d.title}</strong><br>${d.text}<br><span class="tag ${d.color}">${d.tag}</span>`;
}

// Draw pie chart
(function drawPie() {
  const svg = document.getElementById('data-pie');
  const data = [
    { label: 'Common Crawl', pct: 60, color: '#2563eb' },
    { label: 'WebText2', pct: 22, color: '#7c3aed' },
    { label: 'Books1', pct: 8, color: '#16a34a' },
    { label: 'Books2', pct: 8, color: '#ea580c' },
    { label: 'Wikipedia', pct: 3, color: '#dc2626' }
  ];
  const keys = ['cc', 'wt2', 'b1', 'b2', 'wiki'];
  const cx = 110, cy = 110, r = 90;
  let startAngle = -Math.PI / 2;
  
  data.forEach((d, i) => {
    const angle = (d.pct / 101) * 2 * Math.PI; // slightly less than 100 to leave gap
    const endAngle = startAngle + angle;
    const x1 = cx + r * Math.cos(startAngle);
    const y1 = cy + r * Math.sin(startAngle);
    const x2 = cx + r * Math.cos(endAngle);
    const y2 = cy + r * Math.sin(endAngle);
    const largeArc = angle > Math.PI ? 1 : 0;
    
    const path = document.createElementNS('http://www.w3.org/2000/svg', 'path');
    path.setAttribute('d', `M ${cx} ${cy} L ${x1} ${y1} A ${r} ${r} 0 ${largeArc} 1 ${x2} ${y2} Z`);
    path.setAttribute('fill', d.color);
    path.setAttribute('stroke', 'white');
    path.setAttribute('stroke-width', '2');
    path.style.cursor = 'pointer';
    path.style.transition = 'opacity 0.2s';
    path.addEventListener('click', () => showDataInfo(keys[i]));
    path.addEventListener('mouseenter', () => { path.style.opacity = '0.8'; });
    path.addEventListener('mouseleave', () => { path.style.opacity = '1'; });
    svg.appendChild(path);
    
    // Label
    const midAngle = startAngle + angle / 2;
    const lx = cx + (r * 0.6) * Math.cos(midAngle);
    const ly = cy + (r * 0.6) * Math.sin(midAngle);
    if (d.pct > 5) {
      const text = document.createElementNS('http://www.w3.org/2000/svg', 'text');
      text.setAttribute('x', lx);
      text.setAttribute('y', ly);
      text.setAttribute('text-anchor', 'middle');
      text.setAttribute('dominant-baseline', 'middle');
      text.setAttribute('font-size', '11');
      text.setAttribute('font-weight', '700');
      text.setAttribute('fill', 'white');
      text.setAttribute('pointer-events', 'none');
      text.textContent = d.pct + '%';
      svg.appendChild(text);
    }
    
    startAngle = endAngle;
  });
})();

// ========== DEMO 8: Compute calculator ==========
function updateComputeCalc() {
  const gpuFlops = parseFloat(document.getElementById('gpu-select').value); // TFLOPS
  const gpuCount = parseInt(document.getElementById('gpu-count').value);
  const util = parseInt(document.getElementById('util-slider').value) / 100;
  
  document.getElementById('gpu-count-label').textContent = gpuCount.toLocaleString();
  document.getElementById('util-label').textContent = (util * 100).toFixed(0) + '%';
  
  const targetFlops = 3.14e23;
  const effectiveFlopsPerSec = gpuFlops * 1e12 * gpuCount * util;
  const secondsNeeded = targetFlops / effectiveFlopsPerSec;
  const daysNeeded = secondsNeeded / 86400;
  
  // Cost: V100 ~$3/hr, A100 ~$4/hr, H100 ~$5/hr (rough cloud estimates circa 2020-2023)
  const costPerHr = gpuFlops <= 125 ? 3 : gpuFlops <= 312 ? 4 : 5;
  const totalCost = (daysNeeded * 24 * gpuCount * costPerHr);
  
  document.getElementById('compute-days').textContent = daysNeeded < 1 ? (daysNeeded * 24).toFixed(1) + ' hours' : daysNeeded.toFixed(1) + ' days';
  document.getElementById('compute-cost').textContent = '$' + (totalCost / 1e6).toFixed(1) + 'M';
  
  // How much FLOPS this config achieves in the computed time
  const achievedFlops = effectiveFlopsPerSec * daysNeeded * 86400;
  const pct = Math.min(100, (achievedFlops / targetFlops) * 100);
  document.getElementById('compute-gauge').style.width = pct + '%';
  document.getElementById('compute-gauge-val').textContent = pct.toFixed(0) + '%';
  document.getElementById('compute-gauge').style.background = pct >= 95 ? 'var(--green)' : pct >= 50 ? 'var(--orange)' : 'var(--red)';
  
  const exp = Math.floor(Math.log10(achievedFlops));
  const mantissa = (achievedFlops / Math.pow(10, exp)).toFixed(2);
  document.getElementById('compute-flops').textContent = `${mantissa} √ó 10^${exp}`;
}
updateComputeCalc();

// ========== DEMO 9: Benchmarks ==========
const benchmarks = {
  qa: [
    { name: 'TriviaQA', gpt3: 71.2, sota: 68.0 },
    { name: 'NaturalQs', gpt3: 29.9, sota: 36.6 },
    { name: 'WebQs', gpt3: 41.5, sota: 45.1 },
    { name: 'ARC-Easy', gpt3: 70.2, sota: 68.8 },
    { name: 'ARC-Challenge', gpt3: 51.4, sota: 67.8 }
  ],
  cls: [
    { name: 'SST-2', gpt3: 95.3, sota: 96.8 },
    { name: 'MNLI', gpt3: 76.0, sota: 90.8 },
    { name: 'QNLI', gpt3: 74.0, sota: 98.6 },
    { name: 'RTE', gpt3: 72.9, sota: 92.5 },
    { name: 'CB', gpt3: 82.1, sota: 93.9 }
  ],
  reason: [
    { name: 'WinoGrande', gpt3: 77.7, sota: 84.6 },
    { name: 'HellaSwag', gpt3: 78.9, sota: 85.6 },
    { name: 'PIQA', gpt3: 82.8, sota: 83.2 },
    { name: 'StoryCloze', gpt3: 87.7, sota: 91.8 },
    { name: 'ANLI-R3', gpt3: 40.2, sota: 44.4 }
  ],
  gen: [
    { name: 'News Article', gpt3: 88, sota: 100, note: '% human-like' },
    { name: '2-digit Add', gpt3: 100, sota: 100 },
    { name: '2-digit Sub', gpt3: 98.9, sota: 100 },
    { name: '3-digit Add', gpt3: 80.4, sota: 100 },
    { name: 'Word Unscramble', gpt3: 55.4, sota: 100 }
  ]
};

function showBenchCategory(cat) {
  const data = benchmarks[cat];
  const container = document.getElementById('bench-bars');
  container.innerHTML = '';
  
  data.forEach((d, i) => {
    const row = document.createElement('div');
    row.style.cssText = 'display:flex;align-items:center;gap:8px;margin:10px 0;font-family:system-ui,sans-serif;font-size:13px;';
    
    const label = document.createElement('div');
    label.style.cssText = 'min-width:110px;text-align:right;font-weight:600;';
    label.textContent = d.name;
    
    const trackOuter = document.createElement('div');
    trackOuter.style.cssText = 'flex:1;display:flex;flex-direction:column;gap:3px;';
    
    // GPT-3 bar
    const track1 = document.createElement('div');
    track1.style.cssText = 'height:16px;background:#f0f0f0;border-radius:4px;overflow:hidden;position:relative;';
    const fill1 = document.createElement('div');
    fill1.style.cssText = `height:100%;border-radius:4px;background:var(--accent);width:0;transition:width 0.8s cubic-bezier(0.22,1,0.36,1);`;
    const lbl1 = document.createElement('span');
    lbl1.style.cssText = 'position:absolute;right:6px;top:0;height:100%;display:flex;align-items:center;font-size:11px;font-weight:700;color:white;';
    lbl1.textContent = d.gpt3 + '%';
    track1.appendChild(fill1);
    track1.appendChild(lbl1);
    
    // SOTA bar
    const track2 = document.createElement('div');
    track2.style.cssText = 'height:16px;background:#f0f0f0;border-radius:4px;overflow:hidden;position:relative;';
    const fill2 = document.createElement('div');
    fill2.style.cssText = `height:100%;border-radius:4px;background:#94a3b8;width:0;transition:width 0.8s cubic-bezier(0.22,1,0.36,1);`;
    const lbl2 = document.createElement('span');
    lbl2.style.cssText = 'position:absolute;right:6px;top:0;height:100%;display:flex;align-items:center;font-size:11px;font-weight:700;color:white;';
    lbl2.textContent = d.sota + '%';
    track2.appendChild(fill2);
    track2.appendChild(lbl2);
    
    trackOuter.appendChild(track1);
    trackOuter.appendChild(track2);
    
    row.appendChild(label);
    row.appendChild(trackOuter);
    container.appendChild(row);
    
    setTimeout(() => {
      fill1.style.width = d.gpt3 + '%';
      fill2.style.width = d.sota + '%';
    }, i * 100 + 50);
  });
}
showBenchCategory('qa');

// ========== DEMO 10: Limitations ==========
const limitations = {
  repeat: {
    title: 'üîÅ Repetition',
    text: '<strong>The problem:</strong> GPT-3 sometimes gets stuck repeating phrases, especially in long generations. The autoregressive nature means each token depends on the previous ones ‚Äî if the model starts looping, it reinforces the loop.<br><br><strong>Example:</strong> "The cat sat on the mat. The cat sat on the mat. The cat sat on the mat..." This tends to happen more at lower temperatures and longer outputs.<br><br><strong>Mitigation:</strong> Frequency penalties, top-k/top-p sampling, and post-hoc filtering.'
  },
  hallucination: {
    title: 'üåÄ Hallucination',
    text: '<strong>The problem:</strong> GPT-3 generates plausible-sounding but factually incorrect text with high confidence. It has no mechanism to verify claims against reality.<br><br><strong>Example:</strong> "The first person to walk on Mars was Neil Armstrong in 1969." Sounds right, mixes real facts, but is completely wrong.<br><br><strong>Why it happens:</strong> The model optimizes for text that <em>looks probable</em>, not text that <em>is true</em>. Truth and probability are correlated but not identical.'
  },
  reasoning: {
    title: 'üßÆ Reasoning Failures',
    text: '<strong>The problem:</strong> GPT-3 can do simple arithmetic (2-digit addition: 100%) but rapidly degrades with complexity (5-digit addition: ~10%). Multi-step logical reasoning is brittle.<br><br><strong>Example:</strong> "What is 4,521 √ó 783?" ‚Äî GPT-3 will likely give a wrong answer. It hasn\'t "learned" multiplication; it pattern-matches from training examples.<br><br><strong>Root cause:</strong> Next-token prediction doesn\'t naturally decompose into step-by-step computation. Chain-of-thought prompting (discovered later) partially addresses this.'
  },
  bias: {
    title: '‚öñÔ∏è Bias',
    text: '<strong>The problem:</strong> GPT-3 reflects and sometimes amplifies biases from its internet training data. The paper found systematic gender and racial biases.<br><br><strong>Evidence:</strong> When asked "He/She was a [occupation]", the model associated men with "CEO", "legislator", "banker" and women with "nurse", "receptionist", "housekeeper." Religious bias was also documented ‚Äî Islam was disproportionately associated with violence-related terms.<br><br><strong>Ongoing challenge:</strong> Debiasing is an active research area with no complete solution.'
  },
  context: {
    title: 'üìè Limited Context Window',
    text: '<strong>The problem:</strong> GPT-3\'s context window is 2,048 tokens ‚Äî roughly 1,500 words. Anything beyond that is invisible to the model. For few-shot learning, this limits how many examples you can provide.<br><br><strong>Impact:</strong> Long documents can\'t be processed in one go. The model can\'t maintain coherence across very long conversations. Book-length generation is impossible without chunking.<br><br><strong>Future:</strong> Later models expanded to 4K, 8K, 32K, 128K, and beyond ‚Äî but context management remains a core challenge.'
  },
  update: {
    title: 'üìÖ Stale Knowledge',
    text: '<strong>The problem:</strong> GPT-3\'s knowledge is frozen at its training cutoff date (roughly October 2019). It doesn\'t know about COVID-19, the 2020 election, or anything after training ended.<br><br><strong>Impact:</strong> The model will confidently answer questions about current events using outdated information. It has no way to know what it doesn\'t know.<br><br><strong>Mitigation:</strong> Retrieval-augmented generation (RAG), fine-tuning on new data, and tool use were later developed to address this.'
  }
};

function showLimitation(key) {
  const d = limitations[key];
  document.getElementById('limitation-detail').innerHTML = d.text;
}

// ========== DEMO 11: Societal poll ==========
let pollVotes = [0, 0, 0, 0];
let hasVoted = false;

function votePoll(btn, idx) {
  if (hasVoted) return;
  hasVoted = true;
  
  // Simulate some existing votes
  pollVotes = [42, 31, 18, 27];
  pollVotes[idx] += 1;
  const total = pollVotes.reduce((a, b) => a + b, 0);
  
  btn.style.borderColor = 'var(--accent)';
  btn.style.background = 'var(--accent-light)';
  btn.style.fontWeight = '700';
  
  document.getElementById('poll-results').style.display = 'block';
  
  pollVotes.forEach((v, i) => {
    const pct = (v / total * 100).toFixed(0);
    setTimeout(() => {
      document.getElementById('poll-' + i).style.width = pct + '%';
      document.getElementById('poll-v' + i).textContent = pct + '%';
    }, i * 150);
  });
}

// ========== DEMO 5 default animation on scroll ==========
// Auto-trigger param bars when visible
const paramObserver = new IntersectionObserver((entries) => {
  entries.forEach(e => {
    if (e.isIntersecting) {
      animateParamBars();
      paramObserver.unobserve(e.target);
    }
  });
}, { threshold: 0.3 });
const paramDemo = document.getElementById('demo-params');
if (paramDemo) paramObserver.observe(paramDemo);
</script>

</body>
</html>
